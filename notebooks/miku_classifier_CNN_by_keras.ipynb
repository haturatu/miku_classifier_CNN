{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbLVnI_JnnK4"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import os\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import time\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Step1 Scraping images for training model(You should manually remove noise to improve accuracy of classification)"
      ],
      "metadata": {
        "id": "1ayUyZqB1uDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbErYxPenogE",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#Scraping the true data\n",
        "save_dir = Path(\"/miku_classifier/data/true\")\n",
        "save_dir.parent.mkdir(parents=True, exist_ok=True)\n",
        "save_dir.mkdir(exist_ok=True)\n",
        "\n",
        "tag = \"hatsune_miku\"\n",
        "limit = 100\n",
        "total_images = 1000\n",
        "total_pages = total_images // limit\n",
        "\n",
        "base_url = f\"https://danbooru.donmai.us/posts.json\"\n",
        "\n",
        "response = requests.get(base_url)\n",
        "posts = response.json()\n",
        "\n",
        "# Download\n",
        "for page in range(1, total_pages + 1):\n",
        "    params = {\n",
        "        'tags': tag,\n",
        "        'limit': limit,\n",
        "        'page': page\n",
        "    }\n",
        "    response = requests.get(base_url, params=params)\n",
        "    posts = response.json()\n",
        "\n",
        "    if not posts:\n",
        "        print(\"No more images found.\")\n",
        "        break\n",
        "\n",
        "    for i, post in enumerate(posts):\n",
        "        if 'file_url' in post:\n",
        "            image_url = post['file_url']\n",
        "            try:\n",
        "                img_data = requests.get(image_url)\n",
        "                image = Image.open(BytesIO(img_data.content))\n",
        "                ext = image.format.lower()\n",
        "                filename = os.path.join(save_dir, f\"miku_{(page - 1) * limit + i + 1}.{ext}\")\n",
        "                image.save(filename)\n",
        "                print(f\"Saved: {filename}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to save image {i}: {e}\")\n",
        "\n",
        "    #Sleep to avoid restrictions\n",
        "    time.sleep(1)\n",
        "\n",
        "print(\"Finished downloading true images.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = Path(\"/miku_classifier/data/true\")\n",
        "\n",
        "image_files = [f for f in save_dir.glob(\"*\") if f.suffix.lower() in [\".jpg\", \".jpeg\", \".png\", \".webp\",\".gif\"]]\n",
        "\n",
        "random.seed(42)\n",
        "random.shuffle(image_files)\n",
        "\n",
        "for i, image_path in enumerate(image_files):\n",
        "    ext = image_path.suffix.lower()\n",
        "    new_name = f\"{i+1:04d}{ext}\"\n",
        "    new_path = save_dir / new_name\n",
        "    image_path.rename(new_path)\n",
        "\n",
        "print(\"Renaming and shuffling complete.\")"
      ],
      "metadata": {
        "id": "YYcoBtwqkKwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Scraping the false data\n",
        "save_dir = Path(\"/miku_classifier/data/false\")\n",
        "save_dir.parent.mkdir(parents=True, exist_ok=True)\n",
        "save_dir.mkdir(exist_ok=True)\n",
        "\n",
        "tag = \"-hatsune_miku -vocaloid\"\n",
        "limit = 100\n",
        "total_images = 1000\n",
        "total_pages = total_images // limit\n",
        "\n",
        "base_url = \"https://danbooru.donmai.us/posts.json\"\n",
        "\n",
        "for page in range(1, total_pages + 1):\n",
        "    params = {\n",
        "        'tags': tag,\n",
        "        'limit': limit,\n",
        "        'page': page\n",
        "    }\n",
        "\n",
        "    response = requests.get(base_url, params=params)\n",
        "    posts = response.json()\n",
        "\n",
        "    if not posts:\n",
        "        print(\"No more images found.\")\n",
        "        break\n",
        "\n",
        "    for i, post in enumerate(posts):\n",
        "        if 'file_url' in post:\n",
        "            image_url = post['file_url']\n",
        "            try:\n",
        "                img_data = requests.get(image_url)\n",
        "                image = Image.open(BytesIO(img_data.content))\n",
        "                ext = image.format.lower()\n",
        "                filename = os.path.join(save_dir, f\"false_{(page - 1) * limit + i + 1}.{ext}\")\n",
        "                image.save(filename)\n",
        "                print(f\"Saved: {filename}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to save image {i}: {e}\")\n",
        "\n",
        "    time.sleep(1)\n",
        "\n",
        "print(\"Finished downloading false images.\")"
      ],
      "metadata": {
        "id": "agq5MGCvjtrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = Path(\"/miku_classifier/data/false\")\n",
        "\n",
        "image_files = [f for f in save_dir.glob(\"*\") if f.suffix.lower() in [\".jpg\", \".jpeg\", \".png\", \".webp\",\".gif\"]]\n",
        "\n",
        "random.seed(42)\n",
        "random.shuffle(image_files)\n",
        "\n",
        "for i, image_path in enumerate(image_files):\n",
        "    ext = image_path.suffix.lower()\n",
        "    new_name = f\"{i+1:04d}{ext}\"\n",
        "    new_path = save_dir / new_name\n",
        "    image_path.rename(new_path)\n",
        "\n",
        "print(\"Renaming and shuffling complete.\")"
      ],
      "metadata": {
        "id": "Y-crvVNQkXzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Step2 training model"
      ],
      "metadata": {
        "id": "gekvWRUW18qR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow numpy matplotlib opencv-python"
      ],
      "metadata": {
        "id": "b6zraOp22PZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def load_and_preprocess_images(image_dir, target_size=(128, 128)):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    image_dir = '/miku_classifier/data/'\n",
        "\n",
        "    true_dir = os.path.join(image_dir, 'true')\n",
        "    for img_name in os.listdir(true_dir):\n",
        "        img_path = os.path.join(true_dir, img_name)\n",
        "        img = load_img(img_path, target_size=target_size)\n",
        "        img = img_to_array(img) / 255.0\n",
        "        images.append(img)\n",
        "        labels.append(1)\n",
        "\n",
        "    false_dir = os.path.join(image_dir, 'false')\n",
        "    for img_name in os.listdir(false_dir):\n",
        "        img_path = os.path.join(false_dir, img_name)\n",
        "        img = load_img(img_path, target_size=target_size)\n",
        "        img = img_to_array(img) / 255.0\n",
        "        images.append(img)\n",
        "        labels.append(0)\n",
        "\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "    return images, labels\n",
        "\n",
        "image_dir = '/miku_classifier/data/'\n",
        "images, labels = load_and_preprocess_images(image_dir)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "5F8_xC5ZUi81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=(128, 128, 3)),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "MHI-FMEl3tEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), batch_size=32)"
      ],
      "metadata": {
        "id": "U1_moPlV64JW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### validating model(The validation accuracy rate is about 80%)"
      ],
      "metadata": {
        "id": "VNQfJLBm57md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_val, y_val, verbose=2)\n",
        "print(f'Validation accuracy: {test_acc}')"
      ],
      "metadata": {
        "id": "9ObhRRWq36c_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### test for arbitrary image(You can designate any image by URL)"
      ],
      "metadata": {
        "id": "q3XWnb0I3yx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import img_to_array"
      ],
      "metadata": {
        "id": "n68kUXiL5Ub7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url_input = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Paste URL here',\n",
        "    description='Image URL:',\n",
        "    layout=widgets.Layout(width='600px')\n",
        ")\n",
        "\n",
        "predict_button = widgets.Button(\n",
        "    description='predict',\n",
        "    button_style='success',\n",
        "    tooltip='predict for designated image'\n",
        ")\n",
        "\n",
        "output = widgets.Output()"
      ],
      "metadata": {
        "id": "kTox8OqH7Y8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image_from_url(url, model, target_size=(128, 128)):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "        display(img)\n",
        "        img = img.resize(target_size)\n",
        "        img = img_to_array(img) / 255.0\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "        prediction = model.predict(img)\n",
        "        return prediction[0][0] > 0.5\n",
        "    except Exception as e:\n",
        "        print(f\"failed: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "2cY5OCv27edg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def on_predict_clicked(b):\n",
        "    with output:\n",
        "        clear_output()\n",
        "        url = url_input.value\n",
        "        result = predict_image_from_url(url, model)\n",
        "        if result is None:\n",
        "            print(\"failed to classify\")\n",
        "        elif result:\n",
        "            print(\"Miku in a picture!\")\n",
        "        else:\n",
        "            print(\"Miku isn't in a picture.\")"
      ],
      "metadata": {
        "id": "5M2CcMYa7j9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_button.on_click(on_predict_clicked)\n",
        "display(url_input, predict_button, output)"
      ],
      "metadata": {
        "id": "BVXu6kLF7oUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "テストに使えそうなURL\n",
        "(T)\n",
        "https://piapro.net/images/ch_img_miku.png\n",
        "https://magicalmirai.com/2024/images/special/gallery/visual/visual_tama_main.jpg\n",
        "https://special.goodsmile.info/mikudayo10th/images/img_product_a.png\n",
        "\n",
        "(F)\n",
        "https://www.ssw.co.jp/products/vocaloid6/megpoid/images/v6Gumi_nbg.png\n",
        "https://kasaneteto.jp/sv/img/sv-teto.png\n",
        "https://life.ja-group.jp/upload/food/vegetable/main/8_1.jpg\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "fR08vdaPHU86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "L1amAqdItCjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/drive/MyDrive/miku_project/data"
      ],
      "metadata": {
        "id": "vtZkUf63tOBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /miku_classifier/data/true /content/drive/MyDrive/miku_project/data"
      ],
      "metadata": {
        "id": "5jJnRdx7tnLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /miku_classifier/data/false /content/drive/MyDrive/miku_project/data"
      ],
      "metadata": {
        "id": "bPLSRGPquPLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gynDFZB3AV_a"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}